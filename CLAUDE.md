# 构音障碍语音助手 - AI 开发指南

> **版本**: 2.0 (Voice Bridge)
> **更新日期**: 2025-12-26
> **核心使命**: 让每一个声音都被听见、被理解

---

##  快速参考卡片

| 阶段 | 核心动作 | 关键工具 |
|------|----------|----------|
| **理解** | 用户意图 → 情境推断 | ASR, LLM, RAG |
| **共情** | 情感识别 → 耐心响应 | Agent, Memory |
| **连接** | 表达转换 → 双向理解 | TTS, 多模态 |

** 核心原则**: 不是"纠正"用户的表达，而是"理解"用户的意图

---

## 哲学基础：从"被听见"到"被理解"

### Carl Rogers 的主动倾听理论

> "以这种新的特殊方式被倾听的人变得更加情绪成熟，更加开放于自己的经验，更少防御性。"

**三个促进条件**:
1. **共情 (Empathy)**: 感受用户的感受
2. **真诚 (Genuineness)**: 不假装理解
3. **无条件积极关注 (Unconditional Positive Regard)**: 不评判

### 应用到 AI Agent

| 人类倾听者 | AI Agent 实现 |
|-----------|---------------|
| 耐心等待 | 不因识别困难就放弃，多次尝试 |
| 确认理解 | "您是想说...对吗？" |
| 情感共鸣 | 识别情绪，调整响应语气 |
| 不打断 | 等待完整表达，不急于推断 |

### "默契"(Moqi) 的多层次理解

中文文化中的"默契"概念 (Chen et al., 2023):
- **表层**: 字面意思的理解
- **中层**: 语境和习惯的理解
- **深层**: 不言而喻的默契

**Agent 实现路径**:
```
表层：ASR 识别 + GER 纠错
  ↓
中层：用户词汇表 + 历史对话 + RAG
  ↓
深层：个性化模型 + 长期记忆 + 情境推断
```

---

## 项目愿景：渐进式沟通桥梁

### 第一阶段：让 AI 听懂
```
用户说话 → ASR识别 → 智能纠错 → 意图推断 → 展示给对方
```

### 第二阶段：双向理解
```
患者 ←→ AI Agent ←→ 健康人/服务人员
         ↑
    适应双方表达方式
```

### 第三阶段：全新沟通模式
```
多模态输入（语音+图片+手势+情境）
      ↓
   AI 理解 + 共情
      ↓
个性化沟通辅助（正常音转换/图片交流/情感陪伴）
```

---

## 核心开发原则

### 1. 渐进式体验
- 默认无障碍设计，但普通人也能用
- 不区分"正常"和"非正常"用户
- 产品本身就是包容的

### 2. 以用户为中心的个性化
```python
# 不是这样
if user.has_dysarthria:
    use_special_model()

# 而是这样
model = adapt_to_user(user.speech_patterns, user.vocabulary, user.context)
```

### 3. 数据贡献激励
- 用户贡献数据 → 获得更好的识别效果
- 语音转正常音分享 → 解决核心痛点的同时收集数据
- 社区排行榜 → 社会认同激励

### 4. 隐私优先
- 本地优先处理
- 用户完全控制数据
- 透明的数据使用说明

---

## 技术架构指导

### ASR 策略
```
云 API (火山引擎/阿里云)  ←→  本地模型 (Whisper/SenseVoice)
         ↑                           ↑
    低延迟/高准确              隐私/离线/个性化
```

**选择逻辑**:
- 在线 + 隐私不敏感 → 云 API
- 离线 + 隐私敏感 → 本地模型
- 个性化需求 → 本地微调模型

### Agent 策略
```
API (Qwen/GLM/Claude)  →  RAG + Memory  →  本地 LLM
         ↑                    ↑                ↑
      快速迭代            个性化知识          完全离线
```

### 个性化层次
1. **Prompt Engineering**: 用户词汇表注入
2. **RAG**: 用户历史对话、偏好、常用表达
3. **Memory**: 长期记忆系统
4. **微调**: 语音模型个性化适应

---

## 数据收集标准

### 音频规范
| 属性 | 标准 |
|------|------|
| 格式 | WAV |
| 采样率 | 16kHz |
| 位深 | 16bit |
| 声道 | Mono |
| 最短时长 | 1秒 |
| 最长时长 | 30秒 |

### 元数据字段
```json
{
  "speaker_id": "匿名ID",
  "age_range": "50-59 / 60-69 / 70-79 / 80+",
  "etiology": "脑卒中 / 帕金森 / 脑瘫 / ALS / 其他",
  "severity": "轻度 / 中度 / 重度",
  "intelligibility_score": "1-5",
  "recording_environment": "安静室内 / 普通室内 / 室外",
  "device": "手机 / 平板 / 电脑",
  "consent_level": "仅研究 / 开源可用"
}
```

### 文本类型
1. **命令句** (2-5字): "打电话", "开灯", "喝水"
2. **日常句** (5-15字): "我想喝一杯水", "明天天气怎么样"
3. **对话句** (开放): 自然对话录制
4. **朗读句** (标准): 覆盖常见音素的句子集

### 采集激励机制
```
免费版: 基础功能
  ↓ 贡献 10 分钟
标准版: 个性化 ASR + 无广告
  ↓ 贡献 30 分钟
高级版: 最高精度 + 语音转正常音分享
  ↓ 贡献 60 分钟
尊享版: 康复训练 + 家属监控 + 优先支持
```

---

## 开发优先级 (当前)

### P0 - 立即执行
1. **数据收集页面**: 类似 Mozilla Common Voice
2. **ASR 本地模型接入**: Whisper/SenseVoice 集成

### P1 - 近期计划
3. **Agent API 接入**: Qwen/GLM/Claude
4. **用户词汇表**: 个性化词汇管理
5. **RAG 知识库**: 用户历史和偏好

### P2 - 中期规划
6. **语音转正常音**: TTS 驱动的语音重建
7. **社交分享**: 生成可分享的"正常"语音
8. **康复训练模块**: 游戏化训练

### P3 - 长期愿景
9. **本地 LLM**: 完全离线 Agent
10. **多模态理解**: 图片+手势+语音
11. **社区生态**: 开源数据集和模型

---

## MCP 工具使用优先级

###  优先使用
| 工具 | 用途 |
|------|------|
| `mcp-ai-forever` | 用户交互反馈 |
| `context7` | 框架文档查询 |
| `sequential-thinking` | 复杂推理 |
| `serena` | 代码符号分析 |

###  按需使用
| 工具 | 用途 | 注意 |
|------|------|------|
| `web-search-prime` | 网络搜索 | 偶尔超时 |

---

## A.C.E. 开发循环

### A - 分析与理解 (Analyze)

1. **用户需求分析**
   - 使用 `Grep`, `Read` 理解现有代码
   - 使用 `serena` 分析代码结构
   - 思考：这个功能如何帮助用户"被理解"？

2. **技术方案设计**
   - 使用 `sequential-thinking` 进行复杂推理
   - 使用 `context7` 查询框架文档
   - 评估：本地 vs 云端？隐私影响？

### C - 编码实施 (Code)

1. **实现顺序**
   ```
   数据模型 → API/接口 → 业务逻辑 → UI 组件 → 测试
   ```

2. **代码风格**
   - TypeScript 严格模式
   - 组件化、可复用
   - 注释说明"为什么"而非"是什么"

3. **持续交互**
   - 使用 `mcp-ai-forever` 定期汇报进度
   - 遇到决策点主动询问用户

### E - 评估与交付 (Evaluate)

1. **功能验证**
   - 是否真正帮助用户被理解？
   - 用户体验是否流畅？
   - 隐私保护是否到位？

2. **交付确认**
   - 使用 `mcp-ai-forever` 展示成果
   - 收集用户反馈
   - 记录后续优化点

---

## 常用命令

```bash
# 前端开发
cd frontend && npm run dev

# 后端开发
cd backend && npm run dev

# 测试
pytest tests/ -v

# 类型检查
npm run typecheck
```

---

## 核心文件索引

| 文件 | 说明 |
|------|------|
| `frontend/src/app/page.tsx` | 主页面/实时转录 |
| `backend/src/index.ts` | 后端入口 |
| `backend/src/services/` | ASR 服务实现 |
| `agent-sdk/` | Agent SDK 核心 |
| `docs/` | 研究文档和规范 |

---

**记住**: 我们不是在做一个"语音识别工具"，而是在搭建一座让每个人都能被理解的桥梁。

